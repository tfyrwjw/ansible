# ------------------------ #
# 基础信息配置
# ------------------------ #
# 是否跳过节点物理资源校验
skip_verify_node: false

# 安装模式
  # 在线 online 
  # 离线 offline
  # 应用于可能没有公网的环境
install_mode: online

# 节点时区
timezone: Asia/Shanghai

# CentOS yum源仓库
  # 基础软件源
# base_yum_repo: http://mirrors.cloud.aliyuncs.com/centos/$releasever/os/$basearch/
  # epel软件源
epel_yum_repo: http://mirrors.aliyun.com/epel/7/$basearch
  # docker-ce源
docker_yum_repo: https://mirrors.aliyun.com/docker-ce/linux/centos/7/$basearch/stable
  # kubernetes源
kubernetes_yum_repo: https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/

# Debian apt源仓库
  # 基础软件源
# base_apt_repo: deb http://mirrors.aliyun.com/{{ ansible_distribution | lower }}/ {{ ansible_distribution_release }} main restricted universe multiverse
  # docker-ce源
docker_apt_repo: deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/{{ ansible_distribution | lower }} {{ ansible_distribution_release }} stable
  # kubernetes源
kubernetes_apt_repo: deb [arch=amd64] https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial main

# ------------------------ #
# Docker 相关参数配置
# ------------------------ #
# Docker版本
docker_version: 19.03.1

# 国内镜像加速(若不需要加速，请将值删去，键保留)
docker_mirror: 
- "https://dockerhub.azk8s.cn"
- "https://quay.azk8s.cn"
# - "https://docker.mirrors.ustc.edu.cn"
# - "https://quay.mirrors.ustc.edu.cn"

# docker日志相关
docker_log_driver: "json-file"
docker_log_level: "warn"
docker_log_max_size: "10m"
docker_log_max_file: 3

# docker容器存储目录
docker_storage_dir: "/var/lib/docker"

# 并行镜像下载数量
docker_max_concurrent_downloads: 10

# ------------------------ #
# load-balancer 相关参数配置
# ------------------------ #
# 私有云：
#    VIP 负载模式：
#       也就是负载均衡器 + keepalived 模式，比如常用的 haproxy + keepalived。
#       本脚本中负载均衡器有 nginx、haproxy、envoy 可供选择，设置 lb_mode 即可进行任意切换。
#       设置 lb_kube_apiserver_ip 即表示启用 keepalived，请先与服务器提供部门协商保留一个IP作为 lb_kube_apiserver_ip，
#       一般 lb 节点组中有两个节点就够了，lb节点组中第一个节点为 keepalived 的 master 节点，剩下的都为 backed 节点。
#
#    节点本地负载模式：
#       只启动负载均衡器，不启用 keepalived（即不设置 lb_kube_apiserver_ip），
#       此时 kubelet 链接 apiserver 地址为 127.0.0.1:lb_kube_apiserver_port。
#       使用此模式时请将 lb 节点组置空。
#
# 公有云：
#    不推荐使用 slb 模式，建议直接使用节点本地负载模式。
#    若使用 slb 模式，请先使用节点本地负载模式进行部署，
#    部署成功后再切换至 slb 模式：
#       将 lb_mode 修改为 slb，将 lb_kube_apiserver_ip 设置为购买到的 slb 内网ip，
#       修改 lb_kube_apiserver_port 为 slb 监听端口。
#    再次运行初始化集群脚本即可切换至 slb 模式。
lb_mode: nginx

# 负载均衡器健康检查端口
lb_kube_apiserver_healthcheck_port: 8081

# 使用负载均衡后集群 apiserver ip
# lb_kube_apiserver_ip: "192.168.56.15"

# 使用负载均衡后集群 apiserver port
lb_kube_apiserver_port: 8443

# 使用nginx进行apiserver负载时使用的nginx镜像
lb_nginx_image: dockerhub.azk8s.cn/library/nginx:1.17.4-alpine

# 使用haproxy进行apiserver负载时使用的haproxy镜像
lb_haproxy_image: dockerhub.azk8s.cn/library/haproxy:2.0.7-alpine
# haproxy监控绑定端口
lb_haproxy_stats_bind_address: 9090
# haproxy监控访问路径
lb_haproxy_stats_uri: "/stats"
# haproxy监控自动刷新时间（秒）
lb_haproxy_stats_refresh: 10
# haproxy监控用户名
lb_haproxy_stats_user: "admin"
# haproxy监控用户密码
lb_haproxy_stats_password: "admin"
# haproxy负载均衡算法，常见如下：
# "roundrobin": 基于服务器权重的轮询
# "leastconn": 基于服务器最小连接数
# "source": 基于请求源IP地址
# "uri": 基于请求的URI
lb_haproxy_balance_alg: "leastconn"

# 启用 ingress NodePort服务的负载均衡 (true/false)
enabel_ingress_nodeport_lb: false
# 启用 ingress tls NodePort服务的负载均衡 (true/false)
enabel_ingress_tls_nodeport_lb: false

# 使用haproxy进行apiserver负载时使用的haproxy镜像
lb_envoy_image: dockerhub.azk8s.cn/envoyproxy/envoy-alpine:v1.11.1
lb_envoy_admin_address_port: 9090

# 使用 vip 负载时使用的 keepalived 镜像
lb_keepalived_image: dockerhub.azk8s.cn/osixia/keepalived:2.0.17
# keepalived auth_type 的 password
lb_keepalived_password: "d0cker"
# 区分多个 instance 的 VRRP 组播，同网段不能重复，取值在0-255之间
lb_keepalived_router_id: 51

# ------------------------ #
# Etcd 相关参数配置
# ------------------------ #

# Etcd证书过期时间（天）
etcd_certs_expired: 3650
# Etcd根证书过期时间（天）
etcd_ca_certs_expired: 36500
# Etcd使用的镜像
etcd_image: gcr.azk8s.cn/google_containers/etcd:3.3.15-0
# Etcd 数据根目录
etcd_data_dir: "/var/lib/etcd"
# Etcd 每日备份时间，默认3，即凌晨3点，取值范围0-23
etcd_backup_hour: "3"
# Etcd 每日备份文件保留时长，默认7天
etcd_backup_expiry: "7"

# ------------------------ #
# kubernetes 相关参数配置
# ------------------------ #

# kubernetes证书过期时间（天）
kube_certs_expired: 3650
# kubernetes根证书过期时间（天）
kube_ca_certs_expired: 36500

# 加入集群token
kubeadm_token: "abcdef.0123456789abcdef"

# k8s 集群 master 节点证书配置，可以添加多个ip和域名（比如增加公网ip和域名）
kube_master_external_ip:
- "8.8.8.8"
kube_master_external_demain:
- "kubernetes.io"

# Pod根容器
pod_infra_container_image: gcr.azk8s.cn/google_containers/pause:3.1
# Redhat 用此镜像
# pod_infra_container_image: registry.access.redhat.com/rhel7/pod-infrastructure:latest

# kubernetes各组件镜像仓库前缀
kube_image_repository: gcr.azk8s.cn/google_containers

# kubernetes版本
kube_version: 1.15.5

# 集群内部dns域名
kube_dns_domain: cluster.local

# 集群pod ip段（不要与node和service网段冲突）
kube_pod_subnet: 10.244.0.0/18

# 集群service ip段（不要与node和pod网段冲突）
kube_service_subnet: 10.244.64.0/18

# NodePort端口范围
kube_service_node_port_range: 30000-32767

# 资源保留相关配置
eviction_hard_imagefs_available: 15%
eviction_hard_memory_available: 100Mi
eviction_hard_nodefs_available: 10%
eviction_hard_nodefs_inodes_free: 5%

# 默认使用kube-proxy的 'iptables' 模式，可选 'ipvs' 模式
kube_proxy_mode: iptables

# Kubelet 根目录
kubelet_root_dir: "/var/lib/kubelet"

# node节点最大pod 数
kube_max_pods: 110

# ------------------------ #
# 集群插件相关参数配置
# ------------------------ #

# 是否等待插件运行成功
wait_plugins_ready: true

# ------------------------ #
# 集群网络插件相关参数配置
# ------------------------ #

# 是否启用网络组建
network_plugins_enabled: true

# 集群网络插件，目前支持flannel, calico, kube-ovn
network_plugin: "flannel"

# 设置 flannel 后端
# flannel_backend: "host-gw"
flannel_backend: "vxlan"
# flannel 镜像地址
flannel_image: quay.azk8s.cn/coreos/flannel:v0.11.0-amd64

# calico mtu
calico_veth_mtu: 1440
# calico 相关镜像
calico_typha_image: dockerhub.azk8s.cn/calico/typha:v3.9.1
calico_cni_image: dockerhub.azk8s.cn/calico/cni:v3.9.1
calico_node_image: dockerhub.azk8s.cn/calico/node:v3.9.1
calico_kube_controllers_image: dockerhub.azk8s.cn/calico/kube-controllers:v3.9.1
calico_pod2daemon_flexvol_image: dockerhub.azk8s.cn/calico/pod2daemon-flexvol:v3.9.1
# 设置 Felix 日志级别(debug, info, warning, error)
calico_felix_log_level: "warning"
# calicoctl image 地址
calicoctl_image: dockerhub.azk8s.cn/calico/ctl:v3.9.1

# kube-ovn master 节点
kube_ovn_master:
- "{{ groups['kube-master'][0] }}"
# kube-ovn 相关镜像
kube_ovn_controller_image: index.alauda.cn/alaudak8s/kube-ovn-controller:v0.7.0
kube_ovn_cni_image: index.alauda.cn/alaudak8s/kube-ovn-cni:v0.7.0
kube_ovn_db_image: index.alauda.cn/alaudak8s/kube-ovn-db:v0.7.0
kube_ovn_node_image: index.alauda.cn/alaudak8s/kube-ovn-node:v0.7.0
# 默认网段设置
kube_ovn_default_cidr: "{{ kube_pod_subnet }}"
kube_ovn_default_gateway: "{{ kube_pod_subnet | ipaddr('net') | ipaddr(1) | ipaddr('address') }}"
kube_ovn_node_switch_cidr: 100.64.0.0/16
kube_ovn_enable_mirror: false

# ------------------------ #
# ingress-controller 相关参数配置
# ------------------------ #

# 是否启用ingress-controller
ingress_controller_enabled: true

# ingress-controller类型(nginx,traefik)
ingress_controller_tpye: nginx
# NodePort svc 监听http协议端口(注意需在NodePort端口范围)
ingress_controller_http_nodeport: 30080
# NodePort svc 监听https协议端口(注意需在NodePort端口范围)
ingress_controller_https_nodeport: 30443

# nginx-ingress 镜像地址
nginx_ingress_image: quay.azk8s.cn/kubernetes-ingress-controller/nginx-ingress-controller:0.26.1

# traefik默认证书过期时间（天）
traefik_certs_expired: 3650
# traefik-ingress-controller 镜像地址
traefik_ingress_image: dockerhub.azk8s.cn/library/traefik:1.7.14

# ------------------------ #
# kubernetes-dashboard 相关参数配置
# ------------------------ #

# 是否启用kubernetes-dashboard 
kubernetesui_dashboard_enabled: true

# kubernetes-dashboard默认证书有效期
kubernetesui_dashboard_certs_expired: 3650

# kubernetes-dashboard 镜像地址
kubernetesui_dashboard_image: dockerhub.azk8s.cn/kubernetesui/dashboard:v2.0.0-beta4
kubernetesui_metrics_scraper_image: dockerhub.azk8s.cn/kubernetesui/metrics-scraper:v1.0.1

# ------------------------ #
# metrics-server 相关参数配置 
# ------------------------ #

# 是否启用metrics-server
metrics_server_enabled: true

# metrics-server image地址
metrics_server_image: gcr.azk8s.cn/google_containers/metrics-server-amd64:v0.3.5

# ------------------------ #
# cert-manager 相关配置
# ------------------------ #

# 是否启用cert-manager
cert_manager_enabled: false

# acme相关配置
acme_email: yourname@gmail.com
acme_server: https://acme-v02.api.letsencrypt.org/directory

# cert-manager 相关 image 地址
cert_manager_cainjector_image: "quay.azk8s.cn/jetstack/cert-manager-cainjector:v0.9.1"
cert_manager_webhook_image: "quay.azk8s.cn/jetstack/cert-manager-webhook:v0.9.1"
cert_manager_controller_image: "quay.azk8s.cn/jetstack/cert-manager-controller:v0.9.1"